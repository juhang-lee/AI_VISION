{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juhang-lee/AI_VISION/blob/main/4_day/2.SSD/SSD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iRX9cWQh2RGX",
        "outputId": "19f109c5-bc0f-4b47-c355-2426d96ffec1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-19 04:43:25--  https://github.com/imguru-mooc/AI_VISION/raw/main/4_day/2.SSD/2.SSD.zip\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/imguru-mooc/AI_VISION/main/4_day/2.SSD/2.SSD.zip [following]\n",
            "--2023-10-19 04:43:25--  https://raw.githubusercontent.com/imguru-mooc/AI_VISION/main/4_day/2.SSD/2.SSD.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23130 (23K) [application/zip]\n",
            "Saving to: ‘2.SSD.zip’\n",
            "\n",
            "2.SSD.zip           100%[===================>]  22.59K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-19 04:43:25 (106 MB/s) - ‘2.SSD.zip’ saved [23130/23130]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/imguru-mooc/AI_VISION/raw/main/4_day/2.SSD/2.SSD.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 2.SSD.zip"
      ],
      "metadata": {
        "id": "G7kCO4Q92g6_",
        "outputId": "1238a0f4-8da0-4002-8b9b-79b597fd3a3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  2.SSD.zip\n",
            "  inflating: create_data_lists.py    \n",
            "  inflating: datasets.py             \n",
            "  inflating: detect.py               \n",
            "  inflating: eval.py                 \n",
            "  inflating: model.py                \n",
            "  inflating: train.py                \n",
            "  inflating: utils.py                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1ePhewWJQfqI43FVkgvWd-uPqHQjI9tv5"
      ],
      "metadata": {
        "id": "WNKoRJi_27V0",
        "outputId": "37e36400-1f07-4a4f-dd65-cb58eef1fbac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ePhewWJQfqI43FVkgvWd-uPqHQjI9tv5\n",
            "To: /content/checkpoint_ssd300.pth.tar\n",
            "100% 105M/105M [00:00<00:00, 122MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
        "!tar xf VOCtest_06-Nov-2007.tar"
      ],
      "metadata": {
        "id": "QewMvyj03sBO",
        "outputId": "6f521afe-4429-439a-d505-d53d5ad80813",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-19 04:44:21--  http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
            "Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n",
            "Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 451020800 (430M) [application/x-tar]\n",
            "Saving to: ‘VOCtest_06-Nov-2007.tar’\n",
            "\n",
            "VOCtest_06-Nov-2007 100%[===================>] 430.13M   234MB/s    in 1.8s    \n",
            "\n",
            "2023-10-19 04:44:23 (234 MB/s) - ‘VOCtest_06-Nov-2007.tar’ saved [451020800/451020800]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from utils import *\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load model checkpoint\n",
        "checkpoint = 'checkpoint_ssd300.pth.tar'\n",
        "checkpoint = torch.load(checkpoint)\n",
        "start_epoch = checkpoint['epoch'] + 1\n",
        "print('\\nLoaded checkpoint from epoch %d.\\n' % start_epoch)\n",
        "model = checkpoint['model']\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Transforms\n",
        "resize = transforms.Resize((300, 300))\n",
        "to_tensor = transforms.ToTensor()\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "\n",
        "def detect(original_image, min_score, max_overlap, top_k, suppress=None):\n",
        "    \"\"\"\n",
        "    Detect objects in an image with a trained SSD300, and visualize the results.\n",
        "\n",
        "    :param original_image: image, a PIL Image\n",
        "    :param min_score: minimum threshold for a detected box to be considered a match for a certain class\n",
        "    :param max_overlap: maximum overlap two boxes can have so that the one with the lower score is not suppressed via Non-Maximum Suppression (NMS)\n",
        "    :param top_k: if there are a lot of resulting detection across all classes, keep only the top 'k'\n",
        "    :param suppress: classes that you know for sure cannot be in the image or you do not want in the image, a list\n",
        "    :return: annotated image, a PIL Image\n",
        "    \"\"\"\n",
        "\n",
        "    # Transform\n",
        "    image = normalize(to_tensor(resize(original_image)))\n",
        "\n",
        "    # Move to default device\n",
        "    image = image.to(device)\n",
        "\n",
        "    # Forward prop.\n",
        "    predicted_locs, predicted_scores = model(image.unsqueeze(0))\n",
        "\n",
        "    # Detect objects in SSD output\n",
        "    det_boxes, det_labels, det_scores = model.detect_objects(predicted_locs, predicted_scores, min_score=min_score,\n",
        "                                                             max_overlap=max_overlap, top_k=top_k)\n",
        "\n",
        "    # Move detections to the CPU\n",
        "    det_boxes = det_boxes[0].to('cpu')\n",
        "\n",
        "    # Transform to original image dimensions\n",
        "    original_dims = torch.FloatTensor(\n",
        "        [original_image.width, original_image.height, original_image.width, original_image.height]).unsqueeze(0)\n",
        "    det_boxes = det_boxes * original_dims\n",
        "\n",
        "    # Decode class integer labels\n",
        "    det_labels = [rev_label_map[l] for l in det_labels[0].to('cpu').tolist()]\n",
        "\n",
        "    # If no objects found, the detected labels will be set to ['0.'], i.e. ['background'] in SSD300.detect_objects() in model.py\n",
        "    if det_labels == ['background']:\n",
        "        # Just return original image\n",
        "        return original_image\n",
        "\n",
        "    # Annotate\n",
        "    annotated_image = original_image\n",
        "    draw = ImageDraw.Draw(annotated_image)\n",
        "    font = ImageFont.truetype(\"./calibril.ttf\", 15)\n",
        "\n",
        "    # Suppress specific classes, if needed\n",
        "    for i in range(det_boxes.size(0)):\n",
        "        if suppress is not None:\n",
        "            if det_labels[i] in suppress:\n",
        "                continue\n",
        "\n",
        "        # Boxes\n",
        "        box_location = det_boxes[i].tolist()\n",
        "        draw.rectangle(xy=box_location, outline=label_color_map[det_labels[i]])\n",
        "        draw.rectangle(xy=[l + 1. for l in box_location], outline=label_color_map[\n",
        "            det_labels[i]])  # a second rectangle at an offset of 1 pixel to increase line thickness\n",
        "        # draw.rectangle(xy=[l + 2. for l in box_location], outline=label_color_map[\n",
        "        #     det_labels[i]])  # a third rectangle at an offset of 1 pixel to increase line thickness\n",
        "        # draw.rectangle(xy=[l + 3. for l in box_location], outline=label_color_map[\n",
        "        #     det_labels[i]])  # a fourth rectangle at an offset of 1 pixel to increase line thickness\n",
        "\n",
        "        # Text\n",
        "        text_size = font.getsize(det_labels[i].upper())\n",
        "        text_location = [box_location[0] + 2., box_location[1] - text_size[1]]\n",
        "        textbox_location = [box_location[0], box_location[1] - text_size[1], box_location[0] + text_size[0] + 4.,\n",
        "                            box_location[1]]\n",
        "        draw.rectangle(xy=textbox_location, fill=label_color_map[det_labels[i]])\n",
        "        draw.text(xy=text_location, text=det_labels[i].upper(), fill='white',\n",
        "                  font=font)\n",
        "    del draw\n",
        "\n",
        "    return annotated_image"
      ],
      "metadata": {
        "id": "dWuO0NWx2roG",
        "outputId": "528fda8d-fc08-4ccb-c4ab-3c766b81ceb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:570: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if d.__name__ is 'adjust_hue':\n",
            "/usr/local/lib/python3.10/dist-packages/torch/serialization.py:888: SourceChangeWarning: source code of class 'model.SSD300' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ac6df072ba06>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load model checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'checkpoint_ssd300.pth.tar'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mstart_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nLoaded checkpoint from epoch %d.\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    813\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1041\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    978\u001b[0m                 \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m                 typed_storage = torch.storage.TypedStorage(\n\u001b[0;32m--> 980\u001b[0;31m                     \u001b[0mwrap_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m                     _internal=True)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[1;32m    167\u001b[0m                            \u001b[0;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                            \u001b[0;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from torchvision import transforms\n",
        "from utils import *\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load model checkpoint\n",
        "checkpoint = 'checkpoint_ssd300.pth.tar'\n",
        "checkpoint = torch.load(checkpoint)\n",
        "start_epoch = checkpoint['epoch'] + 1\n",
        "print('\\nLoaded checkpoint from epoch %d.\\n' % start_epoch)\n",
        "model = checkpoint['model']\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Transforms\n",
        "resize = transforms.Resize((300, 300))\n",
        "to_tensor = transforms.ToTensor()\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])"
      ],
      "metadata": {
        "id": "szvs5aWV9bes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect(original_image, min_score, max_overlap, top_k, suppress=None):\n",
        "    \"\"\"\n",
        "    Detect objects in an image with a trained SSD300, and visualize the results.\n",
        "\n",
        "    :param original_image: image, a PIL Image\n",
        "    :param min_score: minimum threshold for a detected box to be considered a match for a certain class\n",
        "    :param max_overlap: maximum overlap two boxes can have so that the one with the lower score is not suppressed via Non-Maximum Suppression (NMS)\n",
        "    :param top_k: if there are a lot of resulting detection across all classes, keep only the top 'k'\n",
        "    :param suppress: classes that you know for sure cannot be in the image or you do not want in the image, a list\n",
        "    :return: annotated image, a PIL Image\n",
        "    \"\"\"\n",
        "\n",
        "    # Transform\n",
        "    image = normalize(to_tensor(resize(original_image)))\n",
        "\n",
        "    # Move to default device\n",
        "    image = image.to(device)\n",
        "\n",
        "    # Forward prop.\n",
        "    predicted_locs, predicted_scores = model(image.unsqueeze(0))\n",
        "\n",
        "    # Detect objects in SSD output\n",
        "    det_boxes, det_labels, det_scores = model.detect_objects(predicted_locs, predicted_scores, min_score=min_score,\n",
        "                                                             max_overlap=max_overlap, top_k=top_k)\n",
        "\n",
        "    # Move detections to the CPU\n",
        "    det_boxes = det_boxes[0].to('cpu')\n",
        "\n",
        "    # Transform to original image dimensions\n",
        "    original_dims = torch.FloatTensor(\n",
        "        [original_image.width, original_image.height, original_image.width, original_image.height]).unsqueeze(0)\n",
        "    det_boxes = det_boxes * original_dims\n",
        "\n",
        "    # Decode class integer labels\n",
        "    det_labels = [rev_label_map[l] for l in det_labels[0].to('cpu').tolist()]\n",
        "\n",
        "    # If no objects found, the detected labels will be set to ['0.'], i.e. ['background'] in SSD300.detect_objects() in model.py\n",
        "    if det_labels == ['background']:\n",
        "        # Just return original image\n",
        "        return original_image\n",
        "\n",
        "    # Annotate\n",
        "    annotated_image = original_image\n",
        "    draw = ImageDraw.Draw(annotated_image)\n",
        "    font = ImageFont.truetype(\"./calibril.ttf\", 15)\n",
        "\n",
        "    # Suppress specific classes, if needed\n",
        "    for i in range(det_boxes.size(0)):\n",
        "        if suppress is not None:\n",
        "            if det_labels[i] in suppress:\n",
        "                continue\n",
        "\n",
        "        # Boxes\n",
        "        box_location = det_boxes[i].tolist()\n",
        "        draw.rectangle(xy=box_location, outline=label_color_map[det_labels[i]])\n",
        "        draw.rectangle(xy=[l + 1. for l in box_location], outline=label_color_map[\n",
        "            det_labels[i]])  # a second rectangle at an offset of 1 pixel to increase line thickness\n",
        "        # draw.rectangle(xy=[l + 2. for l in box_location], outline=label_color_map[\n",
        "        #     det_labels[i]])  # a third rectangle at an offset of 1 pixel to increase line thickness\n",
        "        # draw.rectangle(xy=[l + 3. for l in box_location], outline=label_color_map[\n",
        "        #     det_labels[i]])  # a fourth rectangle at an offset of 1 pixel to increase line thickness\n",
        "\n",
        "        # Text\n",
        "        text_size = font.getsize(det_labels[i].upper())\n",
        "        # print(text_size)\n",
        "        # text_size = font.getbbox (det_labels[i].upper())\n",
        "        text_location = [box_location[0] + 2., box_location[1] - text_size[1]]\n",
        "        textbox_location = [box_location[0], box_location[1] - text_size[1], box_location[0] + text_size[0] + 4.,\n",
        "                            box_location[1]]\n",
        "        draw.rectangle(xy=textbox_location, fill=label_color_map[det_labels[i]])\n",
        "        draw.text(xy=text_location, text=det_labels[i].upper(), fill='white',\n",
        "                  font=font)\n",
        "    del draw\n",
        "\n",
        "    return annotated_image\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    img_path = '/content/VOCdevkit/VOC2007/JPEGImages/000011.jpg'\n",
        "    original_image = Image.open(img_path, mode='r')\n",
        "    original_image = original_image.convert('RGB')\n",
        "    annotated_image = detect(original_image, min_score=0.2, max_overlap=0.5, top_k=200)\n",
        "\n",
        "    display(annotated_image)"
      ],
      "metadata": {
        "id": "UP2YXvrv3O-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6lpbrPrl9gGe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}